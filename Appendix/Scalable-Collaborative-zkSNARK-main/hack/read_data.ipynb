{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "units = {\n",
    "    \"s\": 1.0,\n",
    "    \"ms\": 0.001,\n",
    "    \"Âµs\": 0.000001,\n",
    "    \"ns\": 0.000000001,\n",
    "    \"bytes\": 1.0 / 1048576,  # 1 MB = 1024 * 1024 B\n",
    "    \"kilo_bytes\": 1.0 / 1024  # 1 KB = 1024 B\n",
    "}\n",
    "\n",
    "batch = 5 # When n is small, the leader MSM occupies a big bottleneck, however, this can be efficiently optimized by parallel the batch MSM.\n",
    "\n",
    "def removeConsecutiveDuplicates(s):\n",
    "    if len(s) < 2:\n",
    "        return s\n",
    "    if s[0] != s[1] or s[0] != '.':\n",
    "        return s[0] + removeConsecutiveDuplicates(s[1:])\n",
    "    return removeConsecutiveDuplicates(s[1:])\n",
    "\n",
    "def splitString(str):\n",
    "    alpha = \"\"\n",
    "    num = \"\"\n",
    "    for i in range(len(str)):\n",
    "        if (str[i].isdigit() or str[i] == '.'):\n",
    "            num = num + str[i]\n",
    "        else:\n",
    "            alpha += str[i]  \n",
    "    return alpha, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sumcheck\n",
    "# data = []\n",
    "\n",
    "# # Read files\n",
    "# for filename in os.listdir('sumcheck'):\n",
    "#     if filename.startswith('sumcheck_') and filename.endswith('.txt'):\n",
    "#         with open(f'sumcheck/{filename}', 'r') as file:\n",
    "#             content = file.readlines()\n",
    "\n",
    "#             record = {'n': None, 'd_time(s)': None, 'd_comm(MB)': None, 'l_time(ms)': None}\n",
    "#             record['n'] = int(re.findall(r'sumcheck_(\\d+)', filename)[0])\n",
    "\n",
    "#             for line in content:\n",
    "#                 if 'End:' in line and 'SumcheckProduct' in line:\n",
    "#                     cleaned_line = removeConsecutiveDuplicates(line)\n",
    "#                     time_string = re.search(r'(\\d+\\.\\d+)(\\D+)', cleaned_line)\n",
    "#                     if time_string:\n",
    "#                         alpha, num = splitString(time_string.group(0))\n",
    "#                         time_in_ms = float(num) * units[alpha.strip()]\n",
    "#                         if 'Distributed' in line:\n",
    "#                             record['d_time(s)'] = time_in_ms\n",
    "#                         else:\n",
    "#                             record['l_time(ms)'] = time_in_ms\n",
    "\n",
    "#                 if 'Comm:' in line:\n",
    "#                     comm = sum(map(int, re.findall(r'(\\d+), (\\d+)', line)[0]))\n",
    "#                     record['d_comm(MB)'] = comm * units['bytes']\n",
    "\n",
    "#             data.append(record)\n",
    "\n",
    "# # Save to .csv\n",
    "# csv_file = 'sumcheck.csv'\n",
    "# with open(csv_file, 'w', newline='') as file:\n",
    "#     writer = csv.DictWriter(file, fieldnames=['n', 'd_time(s)', 'd_comm(MB)', 'l_time(ms)'])\n",
    "#     writer.writeheader()\n",
    "#     for row in data:\n",
    "#         writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_Plonk\n",
    "data = []\n",
    "\n",
    "d_plonk_operations = [\n",
    "    (\"FFT1\", \"local\"),\n",
    "    (\"Compute r\", \"local\"),\n",
    "    (\"Compute t\", \"local\"),\n",
    "    (\"Local DPP\", \"local\"),\n",
    "    (\"DppRand\", \"local\"),\n",
    "    (\"Division\", \"local\"),\n",
    "    (\"FFT2\", \"king\"),\n",
    "    (\"DPP\", \"king\"),\n",
    "    (\"ComToKing\", \"comm\"),\n",
    "    (\"ComFromKing\", \"comm\"),\n",
    "    (\"Opening shares\", \"king\"),\n",
    "    (\"Packing shares\", \"king\"),\n",
    "    (\"Unpack Pack shares\", \"king\"),\n",
    "    (\"Base MSM\", \"msm\")\n",
    "]\n",
    "\n",
    "# Read leader server files\n",
    "for filename in os.listdir('plonk_d'):\n",
    "    if filename.startswith('log_0') and filename.endswith('.txt'):\n",
    "        with open(f'plonk_d/{filename}', 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "            record = {'n': None, 'l': None, 'd_time(s)': 0, 'd_mem(MB)': 0, 'd_comm(MB)': 0, 'local': 0, 'king': 0, \"comm\": 0, \"msm\": 0}\n",
    "            record['n'] = int(re.findall(r'log_0_(\\d+)_(\\d+)', filename)[0][0])\n",
    "            record['l'] = int(re.findall(r'log_0_(\\d+)_(\\d+)', filename)[0][1])\n",
    "            \n",
    "            for line in content:\n",
    "                for op_name, op_var in d_plonk_operations:\n",
    "                    if 'End:' in line and op_name in line:\n",
    "                        cleaned_line = removeConsecutiveDuplicates(line)\n",
    "                        time_string = re.search(r'(\\d+\\.\\d+)(\\D+)', cleaned_line)\n",
    "                        if time_string:\n",
    "                            alpha, num = splitString(time_string.group(0))\n",
    "                            time_in_ms = float(num) * units.get(alpha.strip(), 1)\n",
    "                            record[op_var] = record.get(op_var, 0) + time_in_ms\n",
    "\n",
    "                if 'bytes_sent:' in line:\n",
    "                    bytes_sent = int(re.search(r'bytes_sent: (\\d+)', line).group(1))\n",
    "                    record['d_comm(MB)'] += bytes_sent * units['bytes']\n",
    "\n",
    "                if 'bytes_recv:' in line:\n",
    "                    bytes_recv = int(re.search(r'bytes_recv: (\\d+)', line).group(1))\n",
    "                    record['d_comm(MB)'] += bytes_recv * units['bytes']\n",
    "                    \n",
    "                if 'Maximum resident set size' in line:\n",
    "                    mem = int(re.search(r'(\\d+)', line).group(0))\n",
    "                    record['d_mem(MB)'] = mem * units['kilo_bytes']\n",
    "\n",
    "             # Calculate total time\n",
    "            record['d_time(s)'] = record['local'] + record['king'] + record['comm'] + record['msm']\n",
    "            \n",
    "            data.append(record)\n",
    "\n",
    "# Sort data by 'n' in ascending order\n",
    "data = sorted(data, key=lambda x: x['n'])\n",
    "\n",
    "# Save to .csv\n",
    "csv_file = 'plonk_d.csv'\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['n', 'l', 'd_time(s)', 'd_mem(MB)', 'd_comm(MB)', 'local','king', \"comm\", \"msm\"])\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "data = []\n",
    "\n",
    "# Read worker server files\n",
    "for filename in os.listdir('plonk_d'):\n",
    "    if filename.startswith('log_1_') and filename.endswith('.txt'):\n",
    "        with open(f'plonk_d/{filename}', 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "            record = {'n': None, 'l': None, 'd_time(s)': 0, 'd_mem(MB)': 0, 'd_comm(MB)': 0, 'local': 0, 'king': 0, \"comm\": 0, \"msm\": 0}\n",
    "            record['n'] = int(re.findall(r'log_1_(\\d+)_(\\d+)', filename)[0][0])\n",
    "            record['l'] = int(re.findall(r'log_1_(\\d+)_(\\d+)', filename)[0][1])\n",
    "            \n",
    "            for line in content:\n",
    "                for op_name, op_var in d_plonk_operations:\n",
    "                    if 'End:' in line and op_name in line:\n",
    "                        cleaned_line = removeConsecutiveDuplicates(line)\n",
    "                        time_string = re.search(r'(\\d+\\.\\d+)(\\D+)', cleaned_line)\n",
    "                        if time_string:\n",
    "                            alpha, num = splitString(time_string.group(0))\n",
    "                            time_in_ms = float(num) * units.get(alpha.strip(), 1)\n",
    "                            record[op_var] = record.get(op_var, 0) + time_in_ms\n",
    "\n",
    "                if 'bytes_sent:' in line:\n",
    "                    bytes_sent = int(re.search(r'bytes_sent: (\\d+)', line).group(1))\n",
    "                    record['d_comm(MB)'] += bytes_sent * units['bytes']\n",
    "\n",
    "                if 'bytes_recv:' in line:\n",
    "                    bytes_recv = int(re.search(r'bytes_recv: (\\d+)', line).group(1))\n",
    "                    record['d_comm(MB)'] += bytes_recv * units['bytes']\n",
    "                    \n",
    "                if 'Maximum resident set size' in line:\n",
    "                    mem = int(re.search(r'(\\d+)', line).group(0))\n",
    "                    record['d_mem(MB)'] = mem * units['kilo_bytes']\n",
    "\n",
    "             # Calculate total time\n",
    "            record['d_time(s)'] = record['local'] + record['king'] + record['comm'] + record['msm']\n",
    "            \n",
    "            data.append(record)\n",
    "\n",
    "# Sort data by 'n' in ascending order\n",
    "data = sorted(data, key=lambda x: x['n'])\n",
    "\n",
    "# Save to .csv\n",
    "csv_file = 'plonk_d_worker.csv'\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['n', 'l', 'd_time(s)', 'd_mem(MB)', 'd_comm(MB)', 'local','king', \"comm\", \"msm\"])\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# local_GKR Depth=8\n",
    "data = []\n",
    "\n",
    "operations = [\n",
    "    (\"Commit\", \"poly_comm\"),\n",
    "    (\"GKR Round\", \"sumcheck\"),\n",
    "    (\"Open\", \"poly_comm\"),\n",
    "]\n",
    "\n",
    "# Read files\n",
    "for filename in os.listdir('gkr_local'):\n",
    "    if filename.startswith('gkr_') and filename.endswith('.txt'):\n",
    "        with open(f'gkr_local/{filename}', 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "            record = {'n': None, 'l_time(s)': 0, 'poly_comm': 0, \"sumcheck\": 0}\n",
    "            # +3 for depth 8\n",
    "            record['n'] = int(re.findall(r'gkr_(\\d+)', filename)[0]) + 3\n",
    "            \n",
    "            for line in content:\n",
    "                for op_name, op_var in operations:\n",
    "                    if 'End:' in line and op_name in line:\n",
    "                        cleaned_line = removeConsecutiveDuplicates(line)\n",
    "                        time_string = re.search(r'(\\d+\\.\\d+)(\\D+)', cleaned_line)\n",
    "                        if time_string:\n",
    "                            alpha, num = splitString(time_string.group(0))\n",
    "                            time_in_ms = float(num) * units.get(alpha.strip(), 1)\n",
    "                            record[op_var] = record.get(op_var, 0) + time_in_ms\n",
    "\n",
    "            # Calculate total time\n",
    "            record['l_time(s)'] = (record['sumcheck'] + record['poly_comm']) \n",
    "            \n",
    "            data.append(record)\n",
    "            \n",
    "# Sort data by 'n' in ascending order\n",
    "data = sorted(data, key=lambda x: x['n'])\n",
    "\n",
    "# Save to .csv\n",
    "csv_file = 'gkr_local.csv'\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['n', 'l_time(s)', 'sumcheck', 'poly_comm'])\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_Hyperplonk\n",
    "data = []\n",
    "\n",
    "operations = [\n",
    "    (\"Commit\", \"poly_comm\"),\n",
    "    (\"Gate identity\", \"gate\"),\n",
    "    (\"Wire identity\", \"wire\"),\n",
    "    (\"Open\", \"poly_comm\"),\n",
    "]\n",
    "\n",
    "# Read files\n",
    "for filename in os.listdir('hyperplonk_local'):\n",
    "    if filename.startswith('hyperplonk_') and filename.endswith('.txt'):\n",
    "        with open(f'hyperplonk_local/{filename}', 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "            record = {'n': None, 'l_time(s)': 0, 'poly_comm': 0, \"gate\": 0, \"wire\": 0}\n",
    "            record['n'] = int(re.findall(r'hyperplonk_(\\d+)', filename)[0])\n",
    "            \n",
    "            for line in content:\n",
    "                for op_name, op_var in operations:\n",
    "                    if 'End:' in line and op_name in line:\n",
    "                        cleaned_line = removeConsecutiveDuplicates(line)\n",
    "                        time_string = re.search(r'(\\d+\\.\\d+)(\\D+)', cleaned_line)\n",
    "                        if time_string:\n",
    "                            alpha, num = splitString(time_string.group(0))\n",
    "                            time_in_ms = float(num) * units.get(alpha.strip(), 1)\n",
    "                            record[op_var] = record.get(op_var, 0) + time_in_ms\n",
    "\n",
    "            # Calculate total time\n",
    "            record['l_time(s)'] = (record['gate'] + record['wire'] + record['poly_comm']) \n",
    "            \n",
    "            data.append(record)\n",
    "            \n",
    "# Sort data by 'n' in ascending order\n",
    "data = sorted(data, key=lambda x: x['n'])\n",
    "\n",
    "# Save to .csv\n",
    "csv_file = 'hyperplonk_local.csv'\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['n', 'l_time(s)', 'gate', 'wire', 'poly_comm'])\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# d_GKR Depth=8\n",
    "data = []\n",
    "\n",
    "operations = [\n",
    "    (\"Comm:\", \"Comm\"),\n",
    "    (\"Local:\", \"Local\"),\n",
    "    (\"Leader:\", \"Leader\"),\n",
    "    (\"Leader: Compute element (MSM Leader)\", \"LeaderMSM\"),\n",
    "]\n",
    "\n",
    "# Read files\n",
    "for filename in os.listdir('gkr_d'):\n",
    "    if filename.startswith('log_0') and filename.endswith('.txt'):\n",
    "        with open(f'gkr_d/{filename}', 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "            record = {'n': None, 'l': None, 'd_time(s)': 0, 'd_comm(MB)': 0, 'Comm': 0, \"Local\": 0, \"Leader\": 0, \"LeaderMSM\": 0}\n",
    "            # +3 for depth 8\n",
    "            record['n'] = int(re.findall(r'log_0_(\\d+)_(\\d+)', filename)[0][0]) + 3 \n",
    "            record['l'] = int(re.findall(r'log_0_(\\d+)_(\\d+)', filename)[0][1])\n",
    "            \n",
    "            for line in content:\n",
    "                for op_name, op_var in operations:\n",
    "                    if 'End:' in line and op_name in line:\n",
    "                        cleaned_line = removeConsecutiveDuplicates(line)\n",
    "                        time_string = re.search(r'(\\d+\\.\\d+)(\\D+)', cleaned_line)\n",
    "                        if time_string:\n",
    "                            alpha, num = splitString(time_string.group(0))\n",
    "                            time_in_ms = float(num) * units.get(alpha.strip(), 1)\n",
    "                            record[op_var] = record.get(op_var, 0) + time_in_ms\n",
    "\n",
    "                if 'Comm:' in line:\n",
    "                    matches = re.findall(r'(\\d+), (\\d+)', line)\n",
    "                    if matches:\n",
    "                        comm = sum(map(int, matches[0]))\n",
    "                        record['d_comm(MB)'] = comm * units['bytes']\n",
    "\n",
    "\n",
    "             # Calculate total time\n",
    "            record['d_time(s)'] = record['Comm'] + record['Local'] + record['Leader'] - record['LeaderMSM'] + record['LeaderMSM'] / batch\n",
    "                       \n",
    "            data.append(record)\n",
    "            \n",
    "# Sort data by 'n' in ascending order\n",
    "data = sorted(data, key=lambda x: x['n'])\n",
    "\n",
    "# Save to .csv\n",
    "csv_file = 'gkr_d.csv'\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['n', 'l', 'd_time(s)', 'd_comm(MB)', 'Comm', 'Local', 'Leader', 'LeaderMSM'])\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# d_Hyperplonk l=32 d=8\n",
    "data = []\n",
    "\n",
    "operations = [\n",
    "    (\"Comm:\", \"Comm\"),\n",
    "    (\"Local:\", \"Local\"),\n",
    "    (\"Leader:\", \"Leader\"),\n",
    "    (\"Leader: Compute element (MSM Leader)\", \"LeaderMSM\"),\n",
    "]\n",
    "\n",
    "# Read files\n",
    "for filename in os.listdir('hyperplonk_d'):\n",
    "    if filename.startswith('log_0') and filename.endswith('.txt'):\n",
    "        with open(f'hyperplonk_d/{filename}', 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "            record = {'n': None, 'd_time(s)': 0, 'd_comm(MB)': 0, 'Comm': 0, \"Local\": 0, \"Leader\": 0, \"LeaderMSM\": 0}\n",
    "            record['n'] = int(re.findall(r'log_0_(\\d+)_(\\d+)', filename)[0][0])\n",
    "            record['l'] = int(re.findall(r'log_0_(\\d+)_(\\d+)', filename)[0][1])\n",
    "            \n",
    "            for line in content:\n",
    "                for op_name, op_var in operations:\n",
    "                    if 'End:' in line and op_name in line:\n",
    "                        cleaned_line = removeConsecutiveDuplicates(line)\n",
    "                        time_string = re.search(r'(\\d+\\.\\d+)(\\D+)', cleaned_line)\n",
    "                        if time_string:\n",
    "                            alpha, num = splitString(time_string.group(0))\n",
    "                            time_in_ms = float(num) * units.get(alpha.strip(), 1)\n",
    "                            record[op_var] = record.get(op_var, 0) + time_in_ms\n",
    "\n",
    "                if 'Comm:' in line:\n",
    "                    matches = re.findall(r'(\\d+), (\\d+)', line)\n",
    "                    if matches:\n",
    "                        comm = sum(map(int, matches[0]))\n",
    "                        record['d_comm(MB)'] = comm * units['bytes']\n",
    "\n",
    "             # Calculate total time\n",
    "            record['d_time(s)'] = record['Comm'] + record['Local'] + record['Leader'] - record['LeaderMSM'] + record['LeaderMSM'] / batch\n",
    "            \n",
    "            data.append(record)\n",
    "\n",
    "# Sort data by 'n' in ascending order\n",
    "data = sorted(data, key=lambda x: x['n'])\n",
    "\n",
    "# Save to .csv\n",
    "csv_file = 'hyperplonk_d.csv'\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['n', 'l', 'd_time(s)', 'd_comm(MB)', 'Comm', 'Local', 'Leader', 'LeaderMSM'])\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_GKR Depth=8 w=21 varying parties\n",
    "w = 21\n",
    "n = w + 3\n",
    "data = []\n",
    "\n",
    "operations = [\n",
    "    (\"Comm:\", \"Comm\"),\n",
    "    (\"Local:\", \"Local\"),\n",
    "    (\"Leader:\", \"Leader\"),\n",
    "    (\"Leader: Compute element (MSM Leader)\", \"LeaderMSM\"),\n",
    "]\n",
    "\n",
    "# Read files\n",
    "for filename in os.listdir('gkr_d'):\n",
    "    if filename.startswith(f'log_0_{w}') and filename.endswith('.txt'):\n",
    "        with open(f'gkr_d/{filename}', 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "            record = {'parties': None, 'n': n, 'd_time(s)': 0, 'd_comm(MB)': 0, 'Comm': 0, \"Local\": 0, \"Leader\": 0, \"LeaderMSM\": 0}\n",
    "            l = int(re.findall(fr'log_0_{w}_(\\d+)', filename)[0]) # also k in the paper\n",
    "            record['parties'] = l * 4 # party = 2^L * 4 where 4 is the packing factor\n",
    "            \n",
    "            for line in content:\n",
    "                for op_name, op_var in operations:\n",
    "                    if 'End:' in line and op_name in line:\n",
    "                        cleaned_line = removeConsecutiveDuplicates(line)\n",
    "                        time_string = re.search(r'(\\d+\\.\\d+)(\\D+)', cleaned_line)\n",
    "                        if time_string:\n",
    "                            alpha, num = splitString(time_string.group(0))\n",
    "                            time_in_ms = float(num) * units.get(alpha.strip(), 1)\n",
    "                            record[op_var] = record.get(op_var, 0) + time_in_ms\n",
    "\n",
    "                if 'Comm:' in line:\n",
    "                    matches = re.findall(r'(\\d+), (\\d+)', line)\n",
    "                    if matches:\n",
    "                        comm = sum(map(int, matches[0]))\n",
    "                        record['d_comm(MB)'] = comm * units['bytes']\n",
    "\n",
    "             # Calculate total time\n",
    "            record['d_time(s)'] = record['Comm'] + record['Local'] + record['Leader'] - record['LeaderMSM'] + record['LeaderMSM'] / batch          \n",
    "            data.append(record)\n",
    "            \n",
    "# Sort data by 'n' in ascending order\n",
    "data = sorted(data, key=lambda x: x['parties'])\n",
    "\n",
    "# Save to .csv\n",
    "csv_file = 'gkr_l.csv'\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['parties', 'n', 'd_time(s)', 'd_comm(MB)', 'Comm', 'Local', 'Leader', 'LeaderMSM'])\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# d_HyperPlonk n=24 varying parties\n",
    "n = 24\n",
    "data = []\n",
    "\n",
    "operations = [\n",
    "    (\"Comm:\", \"Comm\"),\n",
    "    (\"Local:\", \"Local\"),\n",
    "    (\"Leader:\", \"Leader\"),\n",
    "    (\"Leader: Compute element (MSM Leader)\", \"LeaderMSM\"),\n",
    "]\n",
    "\n",
    "# Read files\n",
    "for filename in os.listdir('hyperplonk_d'):\n",
    "    if filename.startswith(f'log_0_{n}') and filename.endswith('.txt'):\n",
    "        with open(f'hyperplonk_d/{filename}', 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "            record = {'parties': None, 'n': n, 'd_time(s)': 0, 'd_comm(MB)': 0, 'Comm': 0, \"Local\": 0, \"Leader\": 0, \"LeaderMSM\": 0}\n",
    "            l = int(re.findall(fr'log_0_{n}_(\\d+)', filename)[0]) # also k in the paper\n",
    "            record['parties'] = l * 4 # party = 2^L * 4 where 4 is the packing factor\n",
    "            \n",
    "            for line in content:\n",
    "                for op_name, op_var in operations:\n",
    "                    if 'End:' in line and op_name in line:\n",
    "                        cleaned_line = removeConsecutiveDuplicates(line)\n",
    "                        time_string = re.search(r'(\\d+\\.\\d+)(\\D+)', cleaned_line)\n",
    "                        if time_string:\n",
    "                            alpha, num = splitString(time_string.group(0))\n",
    "                            time_in_ms = float(num) * units.get(alpha.strip(), 1)\n",
    "                            record[op_var] = record.get(op_var, 0) + time_in_ms\n",
    "\n",
    "                if 'Comm:' in line:\n",
    "                    matches = re.findall(r'(\\d+), (\\d+)', line)\n",
    "                    if matches:\n",
    "                        comm = sum(map(int, matches[0]))\n",
    "                        record['d_comm(MB)'] = comm * units['bytes']\n",
    "\n",
    "             # Calculate total time\n",
    "            record['d_time(s)'] = record['Comm'] + record['Local'] + record['Leader'] - record['LeaderMSM'] + record['LeaderMSM'] / batch        \n",
    "            data.append(record)\n",
    "\n",
    "# Sort data by 'n' in ascending order\n",
    "data = sorted(data, key=lambda x: x['parties'])\n",
    "\n",
    "# Save to .csv\n",
    "csv_file = 'hyperplonk_l.csv'\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['parties', 'n', 'd_time(s)', 'd_comm(MB)', 'Comm', 'Local', 'Leader', 'LeaderMSM'])\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
