// Copyright 2020 ConsenSys Software Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by gnark DO NOT EDIT

// Modifications Copyright 2023 Tianyi Liu and Tiancheng Xie

package piano

import (
	"crypto/sha256"
	"fmt"
	"math/big"
	"math/bits"
	"runtime"
	"time"

	"github.com/consensys/gnark-crypto/ecc/bn254/fr"
	"github.com/consensys/gnark-crypto/ecc/bn254/fr/dkzg"
	"github.com/consensys/gnark-crypto/ecc/bn254/fr/fft"
	"github.com/consensys/gnark-crypto/ecc/bn254/fr/kzg"
	"github.com/consensys/gnark-crypto/fiat-shamir"
	"github.com/consensys/gnark/backend"
	"github.com/consensys/gnark/internal/backend/bn254/cs"
	"github.com/consensys/gnark/internal/utils"
	"github.com/consensys/gnark/logger"
	"github.com/sunblaze-ucb/simpleMPI/mpi"

	curve "github.com/consensys/gnark-crypto/ecc/bn254"
	bn254witness "github.com/consensys/gnark/internal/backend/bn254/witness"
)

var (
	World *mpi.MPIWorld
)

// Proof denotes a Piano proof generated from M parties each with N rows.
type Proof struct {

	// Commitments to the solution vectors
	LRO [3]dkzg.Digest

	// Commitment to Z, the permutation polynomial
	Z dkzg.Digest

	// Commitments to Hx1, Hx2, Hx3 such that
	// Hx = Hx1 + (X**N) * Hx2 + (X**(2N)) * Hx3 and
	// commitments to Hy1, Hy2, Hy3 such that
	// Hy = Hy1 + (Y**M) * Hy2 + (Y**(2M)) * Hy3
	Hx [3]dkzg.Digest
	Hy [3]kzg.Digest

	// Batch partially opening proof of
	// foldedHx(Y, X) = Hx1(Y, X) + alpha*Hx2(Y, X) + (alpha**2)*Hx3(Y, X),
	// L(Y, X), R(Y, X), O(Y, X), Ql(Y, X), Qr(Y, X), Qm(Y, X), Qo(Y, X),
	// Qk(Y, X), S1(Y, X), S2(Y, X), S3(Y, X),
	// Z(Y, X) on X = alpha
	PartialBatchedProof dkzg.BatchOpeningProof

	// Opening partially proof of Z(Y, X) on X = omegaX*alpha
	PartialZShiftedProof dkzg.OpeningProof

	// Batch opening proof of FoldedHx(Y, alpha), L(Y, alpha), R(Y, alpha), O(Y, alpha),
	// Ql(Y, alpha), Qr(Y, alpha), Qm(Y, alpha), Qo(Y, alpha), Qk(Y, alpha),
	// S1(Y, alpha), S2(Y, alpha), S3(Y, alpha), Z(Y, alpha), z(Y, mu*alpha),
	// FoldedHy(Y) on Y = beta
	BatchedProof kzg.BatchOpeningProof
}

// Prove from the public data
func Prove(spr *cs.SparseR1CS, pk *ProvingKey, fullWitness bn254witness.Witness, opt backend.ProverConfig) (*Proof, error) {
	fmt.Println("Prover started")
	log := logger.Logger().With().Str("curve", spr.CurveID().String()).Int("nbConstraints", len(spr.Constraints)).Str("backend", "piano").Logger()
	start := time.Now()
	// pick a hash function that will be used to derive the challenges
	hFunc := sha256.New()

	// create a transcript manager to apply Fiat Shamir
	fs := fiatshamir.NewTranscript(hFunc, "gamma", "eta", "lambda", "alpha", "beta")

	// result
	proof := &Proof{}

	// compute the constraint system solution
	var solution []fr.Element
	var err error
	if solution, err = spr.Solve(fullWitness, opt); err != nil {
		if !opt.Force {
			return nil, err
		} else {
			// we need to fill solution with random values
			var r fr.Element
			_, _ = r.SetRandom()
			for i := spr.NbPublicVariables + spr.NbSecretVariables; i < len(solution); i++ {
				solution[i] = r
				r.Double(&r)
			}
		}
	}

	fmt.Println("Solution computed")

	// query L, R, O in Lagrange basis, not blinded
	lSmallX, rSmallX, oSmallX := evaluateLROSmallDomainX(spr, pk, solution)

	// save lL, lR, lO, and make a copy of them in
	// canonical basis note that we allocate more capacity to reuse for blinded
	// polynomials
	lCanonicalX, rCanonicalX, oCanonicalX := computeLROCanonicalX(
		lSmallX,
		rSmallX,
		oSmallX,
		&pk.Domain[0],
	)
	if err != nil {
		return nil, err
	}

	// compute kzg commitments of bcL, bcR and bcO
	if err := commitToLRO(lCanonicalX, rCanonicalX, oCanonicalX, proof, pk.Vk.DKZGSRS); err != nil {
		return nil, err
	}

	// The first challenge is derived using the public data: the commitments to the permutation,
	// the coefficients of the circuit, and the public inputs.
	// derive gamma from the Comm(cL), Comm(cR), Comm(cO)
	if err := bindPublicData(&fs, "gamma", *pk.Vk, fullWitness[:spr.NbPublicVariables]); err != nil {
		return nil, err
	}
	gamma, err := deriveRandomness(&fs, "gamma", false, &proof.LRO[0], &proof.LRO[1], &proof.LRO[2])
	if err != nil {
		return nil, err
	}

	// Fiat Shamir this
	eta, err := deriveRandomness(&fs, "eta", false)
	if err != nil {
		return nil, err
	}

	// compute Z, the permutation accumulator polynomial, in canonical basis
	// lL, lR, lO are NOT blinded
	zCanonicalX, err := computeZCanonicalX(
		lSmallX,
		rSmallX,
		oSmallX,
		pk, eta, gamma,
	)
	if err != nil {
		return nil, err
	}

	// commit to z
	// note that we explicitly double the number of tasks for the multi exp
	// in dkzg.Commit
	// this may add additional arithmetic operations, but with smaller tasks
	// we ensure that this commitment is well parallelized, without having a
	// "unbalanced task" making the rest of the code wait too long
	if proof.Z, err = dkzg.Commit(zCanonicalX, pk.Vk.DKZGSRS, runtime.NumCPU()*2); err != nil {
		return nil, err
	}

	// derive lambda from the Comm(L), Comm(R), Comm(O), Com(Z)
	lambda, err := deriveRandomness(&fs, "lambda", false, &proof.Z)
	if err != nil {
		return nil, err
	}

	hx1, hx2, hx3 := computeQuotientCanonicalX(pk, lCanonicalX, rCanonicalX, oCanonicalX, zCanonicalX, eta, gamma, lambda)

	// print vector of hx1, hx2, hx3

	// compute kzg commitments of Hx1, Hx2 and Hx3
	if err := commitToQuotientX(hx1, hx2, hx3, proof, pk.Vk.DKZGSRS); err != nil {
		return nil, err
	}

	// derive alpha
	alpha, err := deriveRandomness(&fs, "alpha", false, &proof.Hx[0], &proof.Hx[1], &proof.Hx[2])
	if err != nil {
		return nil, err
	}

	// open Z at mu*alpha
	var alphaShifted fr.Element
	alphaShifted.Mul(&alpha, &pk.Vk.Generator)
	var zShiftedAlpha []fr.Element
	proof.PartialZShiftedProof, zShiftedAlpha, err = dkzg.Open(
		zCanonicalX,
		alphaShifted,
		pk.Vk.DKZGSRS,
	)
	if err != nil {
		return nil, err
	}

	// foldedHDigest = Comm(Hx1) + (alpha**(N))*Comm(Hx2) + (alpha**(2(N)))*Comm(Hx3)
	var bAlphaPowerN, bSize big.Int
	bSize.SetUint64(pk.Domain[0].Cardinality)
	var alphaPowerN fr.Element
	alphaPowerN.Exp(alpha, &bSize)
	alphaPowerN.ToBigIntRegular(&bAlphaPowerN)
	foldedHxDigest := proof.Hx[2]
	foldedHxDigest.ScalarMultiplication(&foldedHxDigest, &bAlphaPowerN)
	foldedHxDigest.Add(&foldedHxDigest, &proof.Hx[1])
	foldedHxDigest.ScalarMultiplication(&foldedHxDigest, &bAlphaPowerN)
	foldedHxDigest.Add(&foldedHxDigest, &proof.Hx[0])

	// foldedHx = Hx1 + (alpha**(N))*Hx2 + (alpha**(2(N)))*Hx3
	foldedHx := hx3
	utils.Parallelize(len(foldedHx), func(start, end int) {
		for i := start; i < end; i++ {
			foldedHx[i].Mul(&foldedHx[i], &alphaPowerN)
			foldedHx[i].Add(&foldedHx[i], &hx2[i])
			foldedHx[i].Mul(&foldedHx[i], &alphaPowerN)
			foldedHx[i].Add(&foldedHx[i], &hx1[i])
		}
	})

	dkzgOpeningPolys := [][]fr.Element{
		foldedHx,
		lCanonicalX,
		rCanonicalX,
		oCanonicalX,
		pk.Ql,
		pk.Qr,
		pk.Qm,
		pk.Qo,
		pk.Qk,
		pk.S1Canonical,
		pk.S2Canonical,
		pk.S3Canonical,
		zCanonicalX,
	}
	dkzgDigests := []dkzg.Digest{
		foldedHxDigest,
		proof.LRO[0],
		proof.LRO[1],
		proof.LRO[2],
		pk.Vk.Ql,
		pk.Vk.Qr,
		pk.Vk.Qm,
		pk.Vk.Qo,
		pk.Vk.Qk,
		pk.Vk.S[0],
		pk.Vk.S[1],
		pk.Vk.S[2],
		proof.Z,
	}

	// Batch open the first list of polynomials
	var evalsXOnAlpha [][]fr.Element
	proof.PartialBatchedProof, evalsXOnAlpha, err = dkzg.BatchOpenSinglePoint(
		dkzgOpeningPolys,
		dkzgDigests,
		alpha,
		hFunc,
		pk.Vk.DKZGSRS,
	)

	if err != nil {
		return nil, err
	}

	if mpi.SelfRank != 0 {
		log.Debug().Dur("took", time.Since(start)).Msg("prover done")
		if err != nil {
			return nil, err
		}

		return proof, nil
	}

	// DBG check whether constraints are satisfied
	if err := checkConstraintX(
		pk,
		evalsXOnAlpha,
		zShiftedAlpha,
		gamma,
		eta,
		lambda,
		alpha,
	); err != nil {
		return nil, err
	}

	polysCanonicalY := append(evalsXOnAlpha, zShiftedAlpha)
	for i := 0; i < len(polysCanonicalY); i++ {
		globalDomain[0].FFTInverse(polysCanonicalY[i], fft.DIF)
		fft.BitReverse(polysCanonicalY[i])
	}

	// compute Hy in canonical form
	hyCanonical1, hyCanonical2, hyCanonical3 := computeQuotientCanonicalY(pk,
		polysCanonicalY,
		eta,
		gamma,
		lambda,
		alpha,
	)

	// compute kzg commitments of Hy1, Hy2 and Hy3
	if err := commitToQuotientOnY(hyCanonical1, hyCanonical2, hyCanonical3, proof, globalSRS); err != nil {
		return nil, err
	}
	// derive beta
	ts := []*curve.G1Affine{
		&proof.PartialBatchedProof.H,
	}
	for _, digest := range proof.PartialBatchedProof.ClaimedDigests {
		ts = append(ts, &digest)
	}
	for _, digest := range proof.Hy {
		ts = append(ts, &digest)
	}
	beta, err := deriveRandomness(&fs, "beta", true, ts...)
	if err != nil {
		return nil, err
	}

	// foldedHy = Hy1 + (beta**M)*Hy2 + (beta**(2M))*Hy3
	var bBetaPowerM big.Int
	bSize.SetUint64(globalDomain[0].Cardinality)
	var betaPowerM fr.Element
	betaPowerM.Exp(beta, &bSize)
	betaPowerM.ToBigIntRegular(&bBetaPowerM)
	foldedHyDigest := proof.Hy[2]
	foldedHyDigest.ScalarMultiplication(&foldedHyDigest, &bBetaPowerM)
	foldedHyDigest.Add(&foldedHyDigest, &proof.Hy[1])
	foldedHyDigest.ScalarMultiplication(&foldedHyDigest, &bBetaPowerM)
	foldedHyDigest.Add(&foldedHyDigest, &proof.Hy[0])
	foldedHy := hyCanonical3
	utils.Parallelize(len(foldedHy), func(start, end int) {
		for i := start; i < end; i++ {
			foldedHy[i].Mul(&foldedHy[i], &betaPowerM)
			foldedHy[i].Add(&foldedHy[i], &hyCanonical2[i])
			foldedHy[i].Mul(&foldedHy[i], &betaPowerM)
			foldedHy[i].Add(&foldedHy[i], &hyCanonical1[i])
		}
	})

	polysCanonicalY = append(polysCanonicalY, foldedHy)

	// evalsOnBeta := evalPolynomialsAtPoint(openingPolysCanonicalY, beta)
	// DBG check whether constraints are satisfied
	// if err := checkConstraintY(pk.Vk,
	// 	evalsOnBeta,
	// 	gamma,
	// 	eta,
	// 	lambda,
	// 	alpha,
	// 	beta,
	// ); err != nil {
	// 	return nil, err
	// }

	var digestsY []curve.G1Affine
	digestsY = append(digestsY, proof.PartialBatchedProof.ClaimedDigests...)
	digestsY = append(digestsY, proof.PartialZShiftedProof.ClaimedDigest, foldedHyDigest)
	proof.BatchedProof, err = kzg.BatchOpenSinglePoint(
		polysCanonicalY,
		digestsY,
		beta,
		hFunc,
		globalSRS,
	)
	if err != nil {
		return nil, err
	}
	return proof, nil
}

// eval evaluates c at p
func eval(c []fr.Element, p fr.Element) fr.Element {
	var r fr.Element
	for i := len(c) - 1; i >= 0; i-- {
		r.Mul(&r, &p).Add(&r, &c[i])
	}
	return r
}

func evalPolynomialsAtPoint(polys [][]fr.Element, point fr.Element) []fr.Element {
	res := make([]fr.Element, len(polys))
	for i := range polys {
		res[i] = eval(polys[i], point)
	}
	return res
}

func commitToLRO(bcl, bcr, bco []fr.Element, proof *Proof, srs *dkzg.SRS) error {
	n := runtime.NumCPU() / 2
	var err error
	proof.LRO[0], err = dkzg.Commit(bcl, srs, n)
	if err != nil {
		return err
	}
	proof.LRO[1], err = dkzg.Commit(bcr, srs, n)
	if err != nil {
		return err
	}
	proof.LRO[2], err = dkzg.Commit(bco, srs, n)
	return err
}

func commitToQuotientX(h1, h2, h3 []fr.Element, proof *Proof, srs *dkzg.SRS) error {
	n := runtime.NumCPU() / 2
	var err error
	proof.Hx[0], err = dkzg.Commit(h1, srs, n)
	if err != nil {
		return err
	}
	proof.Hx[1], err = dkzg.Commit(h2, srs, n)
	if err != nil {
		return err
	}
	proof.Hx[2], err = dkzg.Commit(h3, srs, n)
	return err
}

func commitToQuotientOnY(h1, h2, h3 []fr.Element, proof *Proof, srs *kzg.SRS) error {
	n := runtime.NumCPU() / 2
	var err error
	proof.Hy[0], err = kzg.Commit(h1, srs, n)
	if err != nil {
		return err
	}
	proof.Hy[1], err = kzg.Commit(h2, srs, n)
	if err != nil {
		return err
	}
	proof.Hy[2], err = kzg.Commit(h3, srs, n)
	return err
}

func computeLROCanonicalX(ll, lr, lo []fr.Element, domain *fft.Domain) (cl, cr, co []fr.Element) {
	cl = make([]fr.Element, domain.Cardinality)
	cr = make([]fr.Element, domain.Cardinality)
	co = make([]fr.Element, domain.Cardinality)

	copy(cl, ll)
	domain.FFTInverse(cl, fft.DIF)
	fft.BitReverse(cl)

	copy(cr, lr)
	domain.FFTInverse(cr, fft.DIF)
	fft.BitReverse(cr)

	copy(co, lo)
	domain.FFTInverse(co, fft.DIF)
	fft.BitReverse(co)
	return
}

// blindPoly blinds a polynomial by adding a Q(X)*(X**degree-1), where deg Q = order.
//
// * cp polynomial in canonical form
// * rou root of unity, meaning the blinding factor is multiple of X**rou-1
// * bo blinding order,  it's the degree of Q, where the blinding is Q(X)*(X**degree-1)
//
// WARNING:
// pre condition degree(cp) ⩽ rou + bo
// pre condition cap(cp) ⩾ int(totalDegree + 1)
func blindPoly(cp []fr.Element, rou, bo uint64) ([]fr.Element, error) {

	// degree of the blinded polynomial is max(rou+order, cp.Degree)
	totalDegree := rou + bo

	// re-use cp
	res := cp[:totalDegree+1]

	// random polynomial
	blindingPoly := make([]fr.Element, bo+1)
	for i := uint64(0); i < bo+1; i++ {
		if _, err := blindingPoly[i].SetRandom(); err != nil {
			return nil, err
		}
	}

	// blinding
	for i := uint64(0); i < bo+1; i++ {
		res[i].Sub(&res[i], &blindingPoly[i])
		res[rou+i].Add(&res[rou+i], &blindingPoly[i])
	}

	return res, nil

}

// evaluateLROSmallDomainX extracts the solution l, r, o, and returns it in lagrange form.
// solution = [ public | secret | internal ]
func evaluateLROSmallDomainX(spr *cs.SparseR1CS, pk *ProvingKey, solution []fr.Element) ([]fr.Element, []fr.Element, []fr.Element) {

	s := int(pk.Domain[0].Cardinality)

	var l, r, o []fr.Element
	l = make([]fr.Element, s)
	r = make([]fr.Element, s)
	o = make([]fr.Element, s)
	s0 := solution[0]

	for i := 0; i < spr.NbPublicVariables; i++ { // placeholders
		l[i] = solution[i]
		r[i] = s0
		o[i] = s0
	}
	offset := spr.NbPublicVariables
	for i := 0; i < len(spr.Constraints); i++ { // constraints
		l[offset+i] = solution[spr.Constraints[i].L.WireID()]
		r[offset+i] = solution[spr.Constraints[i].R.WireID()]
		o[offset+i] = solution[spr.Constraints[i].O.WireID()]
	}
	offset += len(spr.Constraints)

	for i := 0; i < s-offset; i++ { // offset to reach 2**n constraints (where the id of l,r,o is 0, so we assign solution[0])
		l[offset+i] = s0
		r[offset+i] = s0
		o[offset+i] = s0
	}

	return l, r, o

}

// computeZ computes z, in canonical basis, where:
//
// * z of degree n (domainNum.Cardinality)
// * z(1)=1
// 							       (l(g**k)+eta*(g**k)+gamma)*(r(g**k)+eta*u*(g**k)+gamma)*(o(g**k)+eta*(mu**2)*(g**k)+gamma)
// * for i>0: z(g**i) = prod_{k<i} -------------------------------------------------------------------------------------------
//							         (l(g**k)+eta*s1(g**k)+gamma)*(r(g**k)+eta*s2(g**k)+gamma)*(o(g**k)+eta*s3(g**k)+gamma)
//
//	* l, r, o are the solution in Lagrange basis, evaluated on the small domain
func computeZCanonicalX(l, r, o []fr.Element, pk *ProvingKey, eta, gamma fr.Element) ([]fr.Element, error) {
	// note that z has more capacity has its memory is reused for z later on
	z := make([]fr.Element, pk.Domain[0].Cardinality)
	nbElmts := int(pk.Domain[0].Cardinality)
	gInv := make([]fr.Element, pk.Domain[0].Cardinality)

	z[0].SetOne()
	gInv[0].SetOne()

	evaluationIDSmallDomain := getIDSmallDomain(&pk.Domain[0])

	utils.Parallelize(nbElmts-1, func(start, end int) {

		var f [3]fr.Element
		var g [3]fr.Element

		for i := start; i < end; i++ {

			f[0].Mul(&evaluationIDSmallDomain[i], &eta).Add(&f[0], &l[i]).Add(&f[0], &gamma)
			f[1].Mul(&evaluationIDSmallDomain[i+nbElmts], &eta).Add(&f[1], &r[i]).Add(&f[1], &gamma)
			f[2].Mul(&evaluationIDSmallDomain[i+2*nbElmts], &eta).Add(&f[2], &o[i]).Add(&f[2], &gamma)

			g[0].Mul(&evaluationIDSmallDomain[pk.Permutation[i]], &eta).Add(&g[0], &l[i]).Add(&g[0], &gamma)
			g[1].Mul(&evaluationIDSmallDomain[pk.Permutation[i+nbElmts]], &eta).Add(&g[1], &r[i]).Add(&g[1], &gamma)
			g[2].Mul(&evaluationIDSmallDomain[pk.Permutation[i+2*nbElmts]], &eta).Add(&g[2], &o[i]).Add(&g[2], &gamma)

			f[0].Mul(&f[0], &f[1]).Mul(&f[0], &f[2])
			g[0].Mul(&g[0], &g[1]).Mul(&g[0], &g[2])

			gInv[i+1] = g[0]
			z[i+1] = f[0]
		}
	})

	gInv = fr.BatchInvert(gInv)
	for i := 1; i < nbElmts; i++ {
		z[i].Mul(&z[i], &z[i-1]).
			Mul(&z[i], &gInv[i])
	}

	pk.Domain[0].FFTInverse(z, fft.DIF)
	fft.BitReverse(z)

	return z, nil
}

// evaluateXnMinusOneBig evalutes Xᵐ-1 on DomainBig coset
func evaluateXnMinusOneBig(domainBig, domainSmall *fft.Domain) []fr.Element {
	ratio := domainBig.Cardinality / domainSmall.Cardinality
	res := make([]fr.Element, ratio)
	expo := big.NewInt(int64(domainSmall.Cardinality))
	res[0].Exp(domainBig.FrMultiplicativeGen, expo)

	var t fr.Element
	t.Exp(domainBig.Generator, big.NewInt(int64(domainSmall.Cardinality)))

	for i := 1; i < int(ratio); i++ {
		res[i].Mul(&res[i-1], &t)
	}

	var one fr.Element
	one.SetOne()
	for i := 0; i < int(ratio); i++ {
		res[i].Sub(&res[i], &one)
	}

	return res
}

// computeQuotientCanonicalX computes hx in canonical form, split as
// hx1 + (X**N)hx2 + (X**(2N))h3 such that
//
// ql(X)l(X)+qr(X)r(X)+qm(X)l(X)r(X)+qo(X)o(X)+qk(X)
// + lambda * (z(mu*X)*g1(X)*g2(X)*g3(X)-z(X)*f1(X)*f2(X)*f3(X))
// + (lambda**2) * L0(X)*(z(X)-1)
// = hx(X)Zn(X)
func computeQuotientCanonicalX(pk *ProvingKey, lCanonicalX, rCanonicalX, oCanonicalX, zCanonicalX []fr.Element, eta, gamma, lambda fr.Element) ([]fr.Element, []fr.Element, []fr.Element) {
	ratio := pk.Domain[1].Cardinality / pk.Domain[0].Cardinality

	// Compute the power of domain[1].Generator with bit-reversed order.
	factorsBR := make([]fr.Element, ratio)
	factorsBR[0].SetOne()
	for i := 1; i < int(ratio); i++ {
		factorsBR[i].Mul(&factorsBR[i-1], &pk.Domain[1].Generator)
	}
	fft.BitReverse(factorsBR)

	// Variables needed in permutation constraint.
	n := pk.Domain[0].Cardinality
	nn := uint64(64 - bits.TrailingZeros64(uint64(pk.Domain[0].Cardinality)))
	var cosetShiftEta, cosetShiftSquareEta fr.Element
	cosetShiftEta.Mul(&pk.Vk.CosetShift, &eta)
	cosetShiftSquareEta.Mul(&cosetShiftEta, &pk.Vk.CosetShift)

	var one fr.Element
	one.SetOne()
	Lag0 := make([]fr.Element, pk.Domain[0].Cardinality)
	for i := 0; i < int(pk.Domain[0].Cardinality); i++ {
		Lag0[i].Set(&pk.Domain[0].CardinalityInv)
	}

	h := make([]fr.Element, pk.Domain[1].Cardinality)
	for _j := 0; _j < int(ratio); _j++ {
		// Compute FFT part for each polynomial.
		lag0 := pk.Domain[0].FFTPart(Lag0, fft.DIF, factorsBR[_j], true)

		s1 := pk.Domain[0].FFTPart(pk.S1Canonical, fft.DIF, factorsBR[_j], true)
		s2 := pk.Domain[0].FFTPart(pk.S2Canonical, fft.DIF, factorsBR[_j], true)
		s3 := pk.Domain[0].FFTPart(pk.S3Canonical, fft.DIF, factorsBR[_j], true)
		z := pk.Domain[0].FFTPart(zCanonicalX, fft.DIF, factorsBR[_j], true)

		ql := pk.Domain[0].FFTPart(pk.Ql, fft.DIF, factorsBR[_j], true)
		qr := pk.Domain[0].FFTPart(pk.Qr, fft.DIF, factorsBR[_j], true)
		qm := pk.Domain[0].FFTPart(pk.Qm, fft.DIF, factorsBR[_j], true)
		qo := pk.Domain[0].FFTPart(pk.Qo, fft.DIF, factorsBR[_j], true)
		qk := pk.Domain[0].FFTPart(pk.Qk, fft.DIF, factorsBR[_j], true)

		l := pk.Domain[0].FFTPart(lCanonicalX, fft.DIF, factorsBR[_j], true)
		r := pk.Domain[0].FFTPart(rCanonicalX, fft.DIF, factorsBR[_j], true)
		o := pk.Domain[0].FFTPart(oCanonicalX, fft.DIF, factorsBR[_j], true)
	
		hStart := uint64(_j) * n
		utils.Parallelize(int(n), func(start, end int) {
			var f, g [3]fr.Element
			var t0, t1 fr.Element
			var ID fr.Element
			ID.Exp(pk.Domain[0].Generator, big.NewInt(int64(start))).
				Mul(&ID, &factorsBR[_j]).
				Mul(&ID, &pk.Domain[1].FrMultiplicativeGen)
			
			for i := uint64(start); i < uint64(end); i++ {
				_i := bits.Reverse64(uint64(i)) >> nn
				_is := bits.Reverse64(uint64((i + 1)) & (n - 1)) >> nn

				// Compute permutation constraints L0(X)*(z(X)-1)
				h[hStart + _i].Sub(&z[_i], &one).Mul(&h[hStart + _i], &lag0[_i])
				
				// Compute permutation constraints z(mu*X)*g1(X)*g2(X)*g3(X) - z(X)*f1(X)*f2(X)*f3(X)
				f[0].Mul(&ID, &eta).Add(&f[0], &l[_i]).Add(&f[0], &gamma)
				f[1].Mul(&ID, &cosetShiftEta).Add(&f[1], &r[_i]).Add(&f[1], &gamma)
				f[2].Mul(&ID, &cosetShiftSquareEta).Add(&f[2], &o[_i]).Add(&f[2], &gamma)

				g[0].Mul(&s1[_i], &eta).Add(&g[0], &l[_i]).Add(&g[0], &gamma)
				g[1].Mul(&s2[_i], &eta).Add(&g[1], &r[_i]).Add(&g[1], &gamma)
				g[2].Mul(&s3[_i], &eta).Add(&g[2], &o[_i]).Add(&g[2], &gamma)

				f[0].Mul(&f[0], &f[1]).Mul(&f[0], &f[2]).Mul(&f[0], &z[_i])
				g[0].Mul(&g[0], &g[1]).Mul(&g[0], &g[2]).Mul(&g[0], &z[_is])

				f[0].Sub(&g[0], &f[0])
				h[hStart + _i].Mul(&h[hStart + _i], &lambda).Add(&h[hStart + _i], &f[0])
				ID.Mul(&ID, &pk.Domain[0].Generator)

				// Compute gate constraint
				t1.Mul(&qm[_i], &r[_i])
				t1.Add(&t1, &ql[_i])
				t1.Mul(&t1, &l[_i])
	
				t0.Mul(&qr[_i], &r[_i])
				t0.Add(&t0, &t1)
	
				t1.Mul(&qo[_i], &o[_i])
				t0.Add(&t0, &t1).Add(&t0, &qk[_i])
				h[hStart + _i].Mul(&h[hStart + _i], &lambda).Add(&h[hStart + _i], &t0)
			}
		})
	}

	XnMinusOneBig := evaluateXnMinusOneBig(&pk.Domain[1], &pk.Domain[0])
	XnMinusOneBig = fr.BatchInvert(XnMinusOneBig)
	nn2 := uint64(64 - bits.TrailingZeros64(uint64(pk.Domain[1].Cardinality)))
	utils.Parallelize(int(pk.Domain[1].Cardinality), func(start, end int) {
		for _i := uint64(start); _i < uint64(end); _i++ {
			i := bits.Reverse64(_i) >> nn2
			h[_i].Mul(&h[_i], &XnMinusOneBig[i % ratio])
		}
	})
	pk.Domain[1].FFTInverse(h, fft.DIT, true)

	h1 := h[:n]
	h2 := h[n: 2*n]
	h3 := h[2*n: 3*n]

	return h1, h2, h3
}

// computeQuotientCanonicalY computes Hy in canonical form, split as
// Hy1 + (Y**M)Hy2 + (Y**(2M))Hy3 such that
//
// Ql(Y, alpha)L(Y, alpha)+Qr(Y, alpha)R(Y, alpha)+Qm(Y, alpha)L(Y, alpha)R(Y, alpha)+Qo(Y, alpha)O(Y, alpha)+Qk(Y, alpha)
// + lambda * (Z(Y, mu*alpha)*G1(Y, alpha)*G2(Y, alpha)*G3(Y, alpha)
//	 - Z(Y, alpha)*F1(Y, alpha)*F2(Y, alpha)*F3(Y, alpha))
// + lambda**2 * L0(alpha)*(Z(Y, alpha) - 1)
// - Hx(Y, alpha)Z(X) = Hy(Y)Z(Y)
func computeQuotientCanonicalY(pk *ProvingKey, polys [][]fr.Element, eta, gamma, lambda, alpha fr.Element) ([]fr.Element, []fr.Element, []fr.Element) {
	h := make([]fr.Element, globalDomain[1].Cardinality)
	ratio := globalDomain[1].Cardinality / globalDomain[0].Cardinality

	// Compute the power of globalDomain[1].Generator with bit-reversed order.
	factorsBR := make([]fr.Element, ratio)
	factorsBR[0].SetOne()
	for i := 1; i < int(ratio); i++ {
		factorsBR[i].Mul(&factorsBR[i-1], &globalDomain[1].Generator)
	}
	fft.BitReverse(factorsBR)

	// Variables needed in permutation constraint.
	n := globalDomain[0].Cardinality
	var alphaEta, cosetShiftAlphaEta, cosetShiftSquareAlphaEta fr.Element
	alphaEta.Mul(&alpha, &eta)
	cosetShiftAlphaEta.Mul(&alphaEta, &pk.Vk.CosetShift)
	cosetShiftSquareAlphaEta.Mul(&cosetShiftAlphaEta, &pk.Vk.CosetShift)

	var one fr.Element
	one.SetOne()

	var lagrangeAlpha, den fr.Element
	lagrangeAlpha.Set(&alpha).
		Exp(lagrangeAlpha, big.NewInt(int64(pk.Domain[0].Cardinality))).
		Sub(&lagrangeAlpha, &one)
	den.Sub(&alpha, &one).
		Inverse(&den)
	lagrangeAlpha.Mul(&lagrangeAlpha, &den).
		Mul(&lagrangeAlpha, &pk.Domain[0].CardinalityInv)

	var vanishingX fr.Element
	vanishingX.Exp(alpha, big.NewInt(int64(pk.Domain[0].Cardinality)))
	vanishingX.Sub(&vanishingX, &one)

	for idxBR := 0; idxBR < int(ratio); idxBR++ {
		// Compute FFT part for each polynomial.
		foldedHx := globalDomain[0].FFTPart(polys[0], fft.DIF, factorsBR[idxBR], true)
		l := globalDomain[0].FFTPart(polys[1], fft.DIF, factorsBR[idxBR], true)
		r := globalDomain[0].FFTPart(polys[2], fft.DIF, factorsBR[idxBR], true)
		o := globalDomain[0].FFTPart(polys[3], fft.DIF, factorsBR[idxBR], true)
		ql := globalDomain[0].FFTPart(polys[4], fft.DIF, factorsBR[idxBR], true)
		qr := globalDomain[0].FFTPart(polys[5], fft.DIF, factorsBR[idxBR], true)
		qm := globalDomain[0].FFTPart(polys[6], fft.DIF, factorsBR[idxBR], true)
		qo := globalDomain[0].FFTPart(polys[7], fft.DIF, factorsBR[idxBR], true)
		qk := globalDomain[0].FFTPart(polys[8], fft.DIF, factorsBR[idxBR], true)
		s1 := globalDomain[0].FFTPart(polys[9], fft.DIF, factorsBR[idxBR], true)
		s2 := globalDomain[0].FFTPart(polys[10], fft.DIF, factorsBR[idxBR], true)
		s3 := globalDomain[0].FFTPart(polys[11], fft.DIF, factorsBR[idxBR], true)
		z := globalDomain[0].FFTPart(polys[12], fft.DIF, factorsBR[idxBR], true)
		zs := globalDomain[0].FFTPart(polys[13], fft.DIF, factorsBR[idxBR], true)

		hStart := uint64(idxBR) * n
		utils.Parallelize(int(n), func(start, end int) {
			var f, g [3]fr.Element
			var t0, t1 fr.Element
			for _i := uint64(start); _i < uint64(end); _i++ {
				// Compute the permutation constraint L0(alpha)(Z(Y, alpha) - 1)
				h[hStart + _i].Sub(&z[_i], &one).Mul(&h[hStart + _i], &lagrangeAlpha)

				// Compute the permutation constraint  z(Y, u * alpha) * G1(Y, alpha) * G2(Y, alpha) * G3(Y, alpha) - z(Y, alpha) * F1(Y, alpha) * F2(Y, alpha) * F3(Y, alpha)
				f[0].Add(&alphaEta, &l[_i]).Add(&f[0], &gamma)
				f[1].Add(&cosetShiftAlphaEta, &r[_i]).Add(&f[1], &gamma)
				f[2].Add(&cosetShiftSquareAlphaEta, &o[_i]).Add(&f[2], &gamma)

				g[0].Mul(&s1[_i], &eta).Add(&g[0], &l[_i]).Add(&g[0], &gamma)
				g[1].Mul(&s2[_i], &eta).Add(&g[1], &r[_i]).Add(&g[1], &gamma)
				g[2].Mul(&s3[_i], &eta).Add(&g[2], &o[_i]).Add(&g[2], &gamma)

				f[0].Mul(&f[0], &f[1]).Mul(&f[0], &f[2]).Mul(&f[0], &z[_i])
				g[0].Mul(&g[0], &g[1]).Mul(&g[0], &g[2]).Mul(&g[0], &zs[_i])

				f[0].Sub(&g[0], &f[0])
				h[hStart + _i].Mul(&h[hStart + _i], &lambda).Add(&h[hStart + _i], &f[0])

				// Compute the gate constraint.
				t1.Mul(&qm[_i], &r[_i])
				t1.Add(&t1, &ql[_i])
				t1.Mul(&t1, &l[_i])
	
				t0.Mul(&qr[_i], &r[_i])
				t0.Add(&t0, &t1)
	
				t1.Mul(&qo[_i], &o[_i])
				t0.Add(&t0, &t1)
				t0.Add(&t0, &qk[_i])
				h[hStart + _i].Mul(&h[hStart + _i], &lambda).Add(&h[hStart + _i], &t0)

				// Remove Hx(Y, alpha) * (alpha^N - 1)
				t0.Mul(&foldedHx[_i], &vanishingX)
				h[hStart + _i].Sub(&h[hStart + _i], &t0)
			}
		})
	}

	evaluationYmMinusOneInverse := evaluateXnMinusOneBig(globalDomain[1], globalDomain[0])
	evaluationYmMinusOneInverse = fr.BatchInvert(evaluationYmMinusOneInverse)
	nn2 := uint64(64 - bits.TrailingZeros64(uint64(globalDomain[1].Cardinality)))
	utils.Parallelize(int(globalDomain[1].Cardinality), func(start, end int) {
		for _i := uint64(start); _i < uint64(end); _i++ {
			i := bits.Reverse64(_i) >> nn2
			h[_i].Mul(&h[_i], &evaluationYmMinusOneInverse[i % ratio])
		}
	})

	globalDomain[1].FFTInverse(h, fft.DIT, true)

	h1 := h[:globalDomain[0].Cardinality]
	h2 := h[globalDomain[0].Cardinality : 2*globalDomain[0].Cardinality]
	h3 := h[2*globalDomain[0].Cardinality : 3*globalDomain[0].Cardinality]
	return h1, h2, h3
}

// checkConstraintX checks that the constraint is satisfied
func checkConstraintX(pk *ProvingKey, evalsXOnAlpha [][]fr.Element, zShiftedAlpha []fr.Element, gamma, eta, lambda, alpha fr.Element) error {
	var l0, one, den fr.Element
	one.SetOne()
	l0.Exp(alpha, big.NewInt(int64(pk.Domain[0].Cardinality))).Sub(&l0, &one)
	den.Sub(&alpha, &one).Inverse(&den)
	l0.Mul(&l0, &den).Mul(&l0, &pk.Domain[0].CardinalityInv)

	var vanishingX fr.Element
	vanishingX.Exp(alpha, big.NewInt(int64(pk.Domain[0].Cardinality)))
	vanishingX.Sub(&vanishingX, &one)

	for k := 0; k < int(mpi.WorldSize); k++ {
		// unpack vector evalsXOnAlpha on hx, l, r, o, ql, qr, qm, qo, qk, s1, s2, s3, z
		hx := evalsXOnAlpha[0][k]
		l := evalsXOnAlpha[1][k]
		r := evalsXOnAlpha[2][k]
		o := evalsXOnAlpha[3][k]
		ql := evalsXOnAlpha[4][k]
		qr := evalsXOnAlpha[5][k]
		qm := evalsXOnAlpha[6][k]
		qo := evalsXOnAlpha[7][k]
		qk := evalsXOnAlpha[8][k]
		s1 := evalsXOnAlpha[9][k]
		s2 := evalsXOnAlpha[10][k]
		s3 := evalsXOnAlpha[11][k]
		z := evalsXOnAlpha[12][k]
		zs := zShiftedAlpha[k]

		// first part: individual constraints
		var firstPart fr.Element
		ql.Mul(&ql, &l)
		qr.Mul(&qr, &r)
		qm.Mul(&qm, &l).Mul(&qm, &r)
		qo.Mul(&qo, &o)
		firstPart.Add(&ql, &qr).Add(&firstPart, &qm).Add(&firstPart, &qo).Add(&firstPart, &qk)

		// second part:
		// (L(beta, alpha)+eta*S1(beta, alpha)+gamma)*(R(beta, alpha)+eta*S2(beta, alpha)+gamma)*(O(beta, alpha)+eta*S3(alpha)+gamma) * Z(beta,mu*alpha)
		// - (L(beta, alpha)+eta*id1(beta, alpha)+gamma)*(R(beta, alpha)+eta*id2(beta, alpha)+gamma)*(O(beta, alpha)+eta*id3(beta, alpha)+gamma)*Z(beta, alpha)
		s1.Mul(&s1, &eta).Add(&s1, &l).Add(&s1, &gamma)
		s2.Mul(&s2, &eta).Add(&s2, &r).Add(&s2, &gamma)
		s3.Mul(&s3, &eta).Add(&s3, &o).Add(&s3, &gamma)
		s1.Mul(&s1, &s2).Mul(&s1, &s3).Mul(&s1, &zs)

		var alphaEta, ualphaEta, uualphaEta fr.Element
		alphaEta.Mul(&alpha, &eta)
		ualphaEta.Mul(&alphaEta, &pk.Vk.CosetShift)
		uualphaEta.Mul(&ualphaEta, &pk.Vk.CosetShift)

		var secondPart, tmp fr.Element
		secondPart.Add(&alphaEta, &l).Add(&secondPart, &gamma)
		tmp.Add(&ualphaEta, &r).Add(&tmp, &gamma)
		secondPart.Mul(&secondPart, &tmp)
		tmp.Add(&uualphaEta, &o).Add(&tmp, &gamma)
		secondPart.Mul(&secondPart, &tmp).Mul(&secondPart, &z)
		secondPart.Sub(&s1, &secondPart)

		// third part L0(alpha)*(Z(Y, alpha) - 1)
		var thirdPart fr.Element
		thirdPart.Sub(&z, &one).Mul(&thirdPart, &l0)

		// Put it all together
		var result fr.Element
		result.Mul(&thirdPart, &lambda).Add(&result, &secondPart).Mul(&result, &lambda).Add(&result, &firstPart)

		var vH fr.Element
		vH.Mul(&hx, &vanishingX)
		result.Sub(&result, &vH)

		// if result != 0 return error
		if !result.IsZero() {
			return fmt.Errorf("constraints on X are not satisfied on %d: got %s, want 0", k, result.String())
		}
	}
	return nil
}
